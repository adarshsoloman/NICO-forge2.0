"""
Example: Using LLM-Based Semantic Alignment

This script demonstrates how to use the new LLM alignment module
to semantically match English-Hindi text pairs using Rewat's alignment prompt.
"""

from openai import OpenAI
from modules.llm_alignment import align_with_llm, ALIGNMENT_SYSTEM_PROMPT
import config


def main():
    """
    Example usage of LLM-based semantic alignment.
    """
    
    # Sample bilingual corpus (from a PDF page)
    english_text = """
Chapter 3: Photosynthesis

Photosynthesis is the process by which plants make their own food. 
It occurs in the chloroplasts of plant cells. The process requires sunlight, 
water, and carbon dioxide.

The main stages of photosynthesis are light-dependent reactions and 
light-independent reactions. These stages work together to produce glucose.

Plants release oxygen as a byproduct. This oxygen is essential for most 
living organisms on Earth.
    """.strip()
    
    hindi_text = """
рдЕрдзреНрдпрд╛рдп 3: рдкреНрд░рдХрд╛рд╢ рд╕рдВрд╢реНрд▓реЗрд╖рдг

рдкреНрд░рдХрд╛рд╢ рд╕рдВрд╢реНрд▓реЗрд╖рдг рд╡рд╣ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рд╣реИ рдЬрд┐рд╕рдХреЗ рджреНрд╡рд╛рд░рд╛ рдкреМрдзреЗ рдЕрдкрдирд╛ рднреЛрдЬрди рдмрдирд╛рддреЗ рд╣реИрдВред
рдпрд╣ рдкреМрдзреЛрдВ рдХреА рдХреЛрд╢рд┐рдХрд╛рдУрдВ рдХреЗ рдХреНрд▓реЛрд░реЛрдкреНрд▓рд╛рд╕реНрдЯ рдореЗрдВ рд╣реЛрддрд╛ рд╣реИред рдЗрд╕ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреЗ рд▓рд┐рдП 
рд╕реВрд░реНрдп рдХрд╛ рдкреНрд░рдХрд╛рд╢, рдкрд╛рдиреА рдФрд░ рдХрд╛рд░реНрдмрди рдбрд╛рдЗрдСрдХреНрд╕рд╛рдЗрдб рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред

рдкреНрд░рдХрд╛рд╢ рд╕рдВрд╢реНрд▓реЗрд╖рдг рдХреЗ рдореБрдЦреНрдп рдЪрд░рдг рдкреНрд░рдХрд╛рд╢-рдирд┐рд░реНрднрд░ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдПрдВ рдФрд░ рдкреНрд░рдХрд╛рд╢-рд╕реНрд╡рддрдВрддреНрд░ 
рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдПрдВ рд╣реИрдВред рдпреЗ рдЪрд░рдг рдЧреНрд▓реВрдХреЛрдЬ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рд╕рд╛рде рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВред

рдкреМрдзреЗ рдПрдХ рдЙрдк-рдЙрддреНрдкрд╛рдж рдХреЗ рд░реВрдк рдореЗрдВ рдСрдХреНрд╕реАрдЬрди рдЫреЛрдбрд╝рддреЗ рд╣реИрдВред рдпрд╣ рдСрдХреНрд╕реАрдЬрди рдкреГрдереНрд╡реА рдкрд░ 
рдЕрдзрд┐рдХрд╛рдВрд╢ рдЬреАрд╡рд┐рдд рдЬреАрд╡реЛрдВ рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рд╣реИред
    """.strip()
    
    print("=" * 70)
    print("LLM-BASED SEMANTIC ALIGNMENT DEMO")
    print("=" * 70)
    print()
    
    # Show the system prompt being used
    print("ЁЯУЭ SYSTEM PROMPT:")
    print("-" * 70)
    print(ALIGNMENT_SYSTEM_PROMPT[:200] + "...")
    print("-" * 70)
    print()
    
    # Initialize LLM client
    print("ЁЯФз Initializing LLM client...")
    print(f"   Base URL: {config.LLM_BASE_URL}")
    print(f"   Model: {config.LLM_MODEL}")
    print()
    
    client = OpenAI(
        base_url=config.LLM_BASE_URL,
        api_key=config.LLM_API_KEY
    )
    
    # Perform alignment
    print("ЁЯЪА Performing LLM-based semantic alignment...")
    print()
    
    try:
        aligned_pairs = align_with_llm(
            english_text=english_text,
            hindi_text=hindi_text,
            llm_client=client,
            model=config.LLM_MODEL,
            temperature=0.1  # Low temperature for consistency
        )
        
        print(f"тЬЕ Alignment successful! Found {len(aligned_pairs)} pairs")
        print()
        
        # Display results
        print("=" * 70)
        print("ALIGNED TRANSLATION PAIRS")
        print("=" * 70)
        print()
        
        for idx, (eng_chunk, hin_chunk) in enumerate(aligned_pairs, 1):
            print(f"ЁЯУМ Pair {idx}:")
            print()
            print(f"   ЁЯЗмЁЯЗз English ({len(eng_chunk)} chars):")
            print(f"      {eng_chunk}")
            print()
            print(f"   ЁЯЗоЁЯЗ│ Hindi ({len(hin_chunk)} chars):")
            print(f"      {hin_chunk}")
            print()
            print("-" * 70)
            print()
        
        # Summary statistics
        print("=" * 70)
        print("SUMMARY STATISTICS")
        print("=" * 70)
        print(f"Total aligned pairs: {len(aligned_pairs)}")
        
        avg_eng_chars = sum(len(p[0]) for p in aligned_pairs) / len(aligned_pairs)
        avg_hin_chars = sum(len(p[1]) for p in aligned_pairs) / len(aligned_pairs)
        
        print(f"Average English chunk size: {avg_eng_chars:.1f} characters")
        print(f"Average Hindi chunk size: {avg_hin_chars:.1f} characters")
        print(f"Character ratio (EN/HI): {avg_eng_chars/avg_hin_chars:.2f}")
        print()
        
    except Exception as e:
        print(f"тЭМ Alignment failed: {str(e)}")
        print()
        print("Troubleshooting tips:")
        print("  1. Check your API key is valid")
        print("  2. Verify the LLM_BASE_URL is correct")
        print("  3. Ensure you have API credits/quota")
        print("  4. Try a different model if current one fails")
        return
    
    # Show how this compares to index-based alignment
    print("=" * 70)
    print("COMPARISON WITH INDEX-BASED ALIGNMENT")
    print("=" * 70)
    print()
    print("LLM Alignment:")
    print("  тЬЕ Semantically groups related sentences")
    print("  тЬЕ Handles misaligned or complex structures")
    print("  тЬЕ Adapts to natural translation boundaries")
    print("  тЪая╕П  Slower (requires API call)")
    print("  тЪая╕П  Costs API credits")
    print()
    print("Index Alignment:")
    print("  тЬЕ Very fast (no API calls)")
    print("  тЬЕ Deterministic and predictable")
    print("  тЬЕ Works well for aligned PDFs")
    print("  тЪая╕П  Requires strict page alignment")
    print("  тЪая╕П  1:1 sentence mapping only")
    print()


if __name__ == "__main__":
    main()
